{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate everything to save a single data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import utils_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath_BCN = \"./data/Barcelona\"\n",
    "basepath_NAP = \"./data/Naples\"\n",
    "basepath = \"./data/BCN and NAP\"\n",
    "\n",
    "basepath_BCN_FA = os.path.join(basepath_BCN, 'FA')\n",
    "basepath_BCN_GM = os.path.join(basepath_BCN, 'GM')\n",
    "basepath_BCN_RS = os.path.join(basepath_BCN, 'RS')\n",
    "\n",
    "basepath_NAP_FA = os.path.join(basepath_NAP, 'FA')\n",
    "basepath_NAP_GM = os.path.join(basepath_NAP, 'GM')\n",
    "basepath_NAP_RS = os.path.join(basepath_NAP, 'RS')\n",
    "\n",
    "basepath_FA = os.path.join(basepath, 'FA')\n",
    "basepath_GM = os.path.join(basepath, 'GM')\n",
    "basepath_RS = os.path.join(basepath, 'RS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data from Barcelona and Naples separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: renaming filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st: clean scan names to just Pacient ID (only for Naples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in ./data/Naples/FA renamed succesfully.\n",
      "All files in ./data/Naples/GM renamed succesfully.\n",
      "All files in ./data/Naples/RS renamed succesfully.\n"
     ]
    }
   ],
   "source": [
    "utils_cleaner.rename_files_to_first_8_chars(basepath_NAP_FA)\n",
    "utils_cleaner.rename_files_to_first_8_chars(basepath_NAP_GM)\n",
    "utils_cleaner.rename_files_to_first_8_chars(basepath_NAP_RS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd: Create a file with corresponding old ID to new ID using the patient info file (.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_filename_BCN = os.path.join(basepath_BCN, 'subject_clinical_data.xlsx')\n",
    "csv_filename_BCN = os.path.join(basepath_BCN, 'ID_corr_BCN.csv')\n",
    "\n",
    "utils_cleaner.save_ids_to_csv(excel_filename_BCN, csv_filename_BCN, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>002MSVIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>003MSVIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>004MSVIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>005MSVIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>010MSVIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>sFIS_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>sFIS_05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>sFIS_06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>sFIS_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>sFIS_09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID    ID_old\n",
       "0      0  002MSVIS\n",
       "1      1  003MSVIS\n",
       "2      2  004MSVIS\n",
       "3      3  005MSVIS\n",
       "4      4  010MSVIS\n",
       "..   ...       ...\n",
       "160  160   sFIS_04\n",
       "161  161   sFIS_05\n",
       "162  162   sFIS_06\n",
       "163  163   sFIS_07\n",
       "164  164   sFIS_09\n",
       "\n",
       "[165 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_BCN = pd.read_csv(csv_filename_BCN)\n",
    "df_BCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_patients_BCN = len(df_BCN)\n",
    "\n",
    "excel_filename_NAP = os.path.join(basepath_NAP, 'naples2barcelona_multilayer.xlsx')\n",
    "csv_filename_NAP = os.path.join(basepath_NAP, 'ID_corr_NAP.csv')\n",
    "\n",
    "utils_cleaner.save_ids_to_csv(excel_filename_NAP, csv_filename_NAP, number_of_patients_BCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>sub-0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>sub-0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>sub-0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>sub-0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169</td>\n",
       "      <td>sub-0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>265</td>\n",
       "      <td>sub-0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>266</td>\n",
       "      <td>sub-0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>267</td>\n",
       "      <td>sub-0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>268</td>\n",
       "      <td>sub-0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>269</td>\n",
       "      <td>sub-0105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID    ID_old\n",
       "0    165  sub-0001\n",
       "1    166  sub-0002\n",
       "2    167  sub-0003\n",
       "3    168  sub-0004\n",
       "4    169  sub-0005\n",
       "..   ...       ...\n",
       "100  265  sub-0101\n",
       "101  266  sub-0102\n",
       "102  267  sub-0103\n",
       "103  268  sub-0104\n",
       "104  269  sub-0105\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NAP = pd.read_csv(csv_filename_NAP)\n",
    "df_NAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_cleaner.concatenate_csv(df_BCN, df_NAP, 'ID_corr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd: Change file names according to the corresponding id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 0 files.\n",
      "Renamed 0 files.\n",
      "Renamed 0 files.\n"
     ]
    }
   ],
   "source": [
    "# Read the mappings from the CSV file\n",
    "id_to_name_mapping_BCN = utils_cleaner.read_csv_mapping(csv_filename_BCN)\n",
    "\n",
    "# Rename the files in the specified folders\n",
    "utils_cleaner.rename_files_in_folder_removing_suffix(basepath_BCN_FA, id_to_name_mapping_BCN, '_FA_factor.csv')\n",
    "utils_cleaner.rename_files_in_folder_removing_suffix(basepath_BCN_GM, id_to_name_mapping_BCN, '_GM_matrix.csv')\n",
    "utils_cleaner.rename_files_in_folder_removing_suffix(basepath_BCN_RS, id_to_name_mapping_BCN, '_r_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 0 files.\n",
      "Renamed 0 files.\n",
      "Renamed 0 files.\n"
     ]
    }
   ],
   "source": [
    "# Read the mappings from the CSV file\n",
    "id_to_name_mapping_NAP = utils_cleaner.read_csv_mapping(csv_filename_NAP)\n",
    "\n",
    "# Rename the files in the specified folders\n",
    "utils_cleaner.rename_files_in_folder(basepath_NAP_FA, id_to_name_mapping_NAP)\n",
    "utils_cleaner.rename_files_in_folder(basepath_NAP_GM, id_to_name_mapping_NAP)\n",
    "utils_cleaner.rename_files_in_folder(basepath_NAP_RS, id_to_name_mapping_NAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Saving patient's information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVED\n",
    "\n",
    "origin: NAP for Naples, BCN for Barcelona\n",
    "\n",
    "mstype: Nap vs Bcn: RR = 0, SP = 1, PP = 2, (healthy) empty = -1\n",
    "\n",
    "edss: if healthy: Nap empty, Bcn 0 -> unify to 0; else ok\n",
    "\n",
    "dobirth: date of birth\n",
    "\n",
    "doscan: date of scan\n",
    "\n",
    "dostart: date of disease start\n",
    "\n",
    "gender: both have 0 for female, 1 for male\n",
    "\n",
    "\n",
    "#### CALCULATED\n",
    "\n",
    "age = (dobirth - doscan) / 365.25\n",
    "\n",
    "DD: disease duration = (dostart - doscan) / 365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>origin</th>\n",
       "      <th>gender</th>\n",
       "      <th>mstype</th>\n",
       "      <th>edss</th>\n",
       "      <th>dobirth</th>\n",
       "      <th>doscan</th>\n",
       "      <th>dostart</th>\n",
       "      <th>age</th>\n",
       "      <th>DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BCN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1963-09-04</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>1993-01-10</td>\n",
       "      <td>51.53</td>\n",
       "      <td>22.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1959-01-18</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>2007-07-15</td>\n",
       "      <td>58.06</td>\n",
       "      <td>9.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BCN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1956-09-16</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>2010-09-15</td>\n",
       "      <td>60.78</td>\n",
       "      <td>6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1978-02-01</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2007-08-01</td>\n",
       "      <td>37.95</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1964-02-13</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>2007-09-15</td>\n",
       "      <td>52.64</td>\n",
       "      <td>9.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>BCN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>BCN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID origin  gender  mstype  edss     dobirth      doscan     dostart  \\\n",
       "0      0    BCN       1       1   7.5  1963-09-04  2015-03-16  1993-01-10   \n",
       "1      1    BCN       0       2   6.0  1959-01-18  2017-02-08  2007-07-15   \n",
       "2      2    BCN       1       0   3.0  1956-09-16  2017-06-29  2010-09-15   \n",
       "3      3    BCN       0       0   1.5  1978-02-01  2016-01-13  2007-08-01   \n",
       "4      4    BCN       0       0   2.0  1964-02-13  2016-10-04  2007-09-15   \n",
       "..   ...    ...     ...     ...   ...         ...         ...         ...   \n",
       "160  160    BCN       1      -1   0.0         NaN         NaN         NaN   \n",
       "161  161    BCN       0      -1   0.0         NaN         NaN         NaN   \n",
       "162  162    BCN       0      -1   0.0         NaN         NaN         NaN   \n",
       "163  163    BCN       0      -1   0.0         NaN         NaN         NaN   \n",
       "164  164    BCN       0      -1   0.0         NaN         NaN         NaN   \n",
       "\n",
       "       age     DD  \n",
       "0    51.53  22.18  \n",
       "1    58.06   9.57  \n",
       "2    60.78   6.79  \n",
       "3    37.95   8.45  \n",
       "4    52.64   9.05  \n",
       "..     ...    ...  \n",
       "160   0.00   0.00  \n",
       "161   0.00   0.00  \n",
       "162   0.00   0.00  \n",
       "163   0.00   0.00  \n",
       "164   0.00   0.00  \n",
       "\n",
       "[165 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_corr_BCN = os.path.join(basepath_BCN, 'ID_corr_BCN.csv')\n",
    "\n",
    "utils_cleaner.save_columns_to_csv_BCN(excel_filename_BCN, csv_corr_BCN)\n",
    "df_BCN = pd.read_csv(csv_corr_BCN)\n",
    "df_BCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>origin</th>\n",
       "      <th>gender</th>\n",
       "      <th>mstype</th>\n",
       "      <th>edss</th>\n",
       "      <th>dobirth</th>\n",
       "      <th>doscan</th>\n",
       "      <th>dostart</th>\n",
       "      <th>age</th>\n",
       "      <th>DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>NAP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1964-12-05</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>51.97</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>NAP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1977-12-05</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>2009-02-15</td>\n",
       "      <td>38.99</td>\n",
       "      <td>7.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>NAP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000-09-09</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>16.42</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>NAP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1983-04-11</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>2000-08-01</td>\n",
       "      <td>33.78</td>\n",
       "      <td>16.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169</td>\n",
       "      <td>NAP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1982-12-12</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>2011-09-15</td>\n",
       "      <td>33.99</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>265</td>\n",
       "      <td>NAP</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970-07-12</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>266</td>\n",
       "      <td>NAP</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1993-02-17</td>\n",
       "      <td>2016-03-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>267</td>\n",
       "      <td>NAP</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1971-03-16</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>268</td>\n",
       "      <td>NAP</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>2016-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>269</td>\n",
       "      <td>NAP</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1974-06-15</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID origin  gender  mstype  edss     dobirth      doscan     dostart  \\\n",
       "0    165    NAP       0       1   6.0  1964-12-05  2016-11-23  2009-09-01   \n",
       "1    166    NAP       1       1   6.5  1977-12-05  2016-12-02  2009-02-15   \n",
       "2    167    NAP       1       0   2.0  2000-09-09  2017-02-11  2015-07-15   \n",
       "3    168    NAP       0       0   3.5  1983-04-11  2017-01-21  2000-08-01   \n",
       "4    169    NAP       0       0   2.0  1982-12-12  2016-12-09  2011-09-15   \n",
       "..   ...    ...     ...     ...   ...         ...         ...         ...   \n",
       "100  265    NAP       0      -1   0.0  1970-07-12  2017-05-12         NaN   \n",
       "101  266    NAP       1      -1   0.0  1993-02-17  2016-03-03         NaN   \n",
       "102  267    NAP       0      -1   0.0  1971-03-16  2017-04-21         NaN   \n",
       "103  268    NAP       1      -1   0.0  1985-07-01  2016-03-08         NaN   \n",
       "104  269    NAP       0      -1   0.0  1974-06-15  2017-05-26         NaN   \n",
       "\n",
       "       age     DD  \n",
       "0    51.97   7.23  \n",
       "1    38.99   7.79  \n",
       "2    16.42   1.58  \n",
       "3    33.78  16.47  \n",
       "4    33.99   5.23  \n",
       "..     ...    ...  \n",
       "100  46.83   0.00  \n",
       "101  23.04   0.00  \n",
       "102  46.10   0.00  \n",
       "103  30.69   0.00  \n",
       "104  42.95   0.00  \n",
       "\n",
       "[105 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_corr_NAP = os.path.join(basepath_NAP, 'ID_corr_NAP.csv')\n",
    "\n",
    "utils_cleaner.save_columns_to_csv_NAP(excel_filename_NAP, csv_corr_NAP, number_of_patients_BCN)\n",
    "df_NAP = pd.read_csv(csv_corr_NAP)\n",
    "df_NAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the information to concatenated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_cleaner.concatenate_csv(df_BCN, df_NAP, 'ID_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target arrays\n",
    "target_class_BCN = df_BCN[\"mstype\"].values\n",
    "target_BCN = target_class_BCN + 1\n",
    "target_BCN[target_BCN > 1] = 1\n",
    "\n",
    "target_class_NAP = df_NAP[\"mstype\"].values\n",
    "target_NAP = target_class_NAP + 1\n",
    "target_NAP[target_NAP > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  1,  1,  0,  0,  0,  2,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  2,  0,  2, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  1,  0,  0,  1,  0,  0,  1,  1,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "        1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  0,  0,  0,\n",
       "        2,  0,  2,  0,  0,  2,  0,  1,  1,  2,  0,  0,  2,  0,  1,  0,  0,\n",
       "        0,  0,  0,  0,  1,  1,  0,  0,  1,  0,  1,  2,  0,  0,  0,  0,  0,\n",
       "        1,  0,  1,  2,  1,  1,  0,  0,  0,  1,  0,  1,  0, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the target arrays\n",
    "target_class = np.concatenate((target_class_BCN, target_class_NAP))\n",
    "target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the target arrays\n",
    "target = np.concatenate((target_BCN, target_NAP))\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to target_class.npy\n",
      "Data saved to target.npy\n"
     ]
    }
   ],
   "source": [
    "# Save the targets to a .npy file\n",
    "np.save(os.path.join(basepath, 'target_class.npy'), target_class)\n",
    "print(\"Data saved to target_class.npy\")\n",
    "np.save(os.path.join(basepath, 'target.npy'), target)\n",
    "print(\"Data saved to target.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list with all input filenames, using the ID of each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000.csv',\n",
       " '0001.csv',\n",
       " '0002.csv',\n",
       " '0003.csv',\n",
       " '0004.csv',\n",
       " '0005.csv',\n",
       " '0006.csv',\n",
       " '0007.csv',\n",
       " '0008.csv',\n",
       " '0009.csv',\n",
       " '0010.csv',\n",
       " '0011.csv',\n",
       " '0012.csv',\n",
       " '0013.csv',\n",
       " '0014.csv',\n",
       " '0015.csv',\n",
       " '0016.csv',\n",
       " '0017.csv',\n",
       " '0018.csv',\n",
       " '0019.csv',\n",
       " '0020.csv',\n",
       " '0021.csv',\n",
       " '0022.csv',\n",
       " '0023.csv',\n",
       " '0024.csv',\n",
       " '0025.csv',\n",
       " '0026.csv',\n",
       " '0027.csv',\n",
       " '0028.csv',\n",
       " '0029.csv',\n",
       " '0030.csv',\n",
       " '0031.csv',\n",
       " '0032.csv',\n",
       " '0033.csv',\n",
       " '0034.csv',\n",
       " '0035.csv',\n",
       " '0036.csv',\n",
       " '0037.csv',\n",
       " '0038.csv',\n",
       " '0039.csv',\n",
       " '0040.csv',\n",
       " '0041.csv',\n",
       " '0042.csv',\n",
       " '0043.csv',\n",
       " '0044.csv',\n",
       " '0045.csv',\n",
       " '0046.csv',\n",
       " '0047.csv',\n",
       " '0048.csv',\n",
       " '0049.csv',\n",
       " '0050.csv',\n",
       " '0051.csv',\n",
       " '0052.csv',\n",
       " '0053.csv',\n",
       " '0054.csv',\n",
       " '0055.csv',\n",
       " '0056.csv',\n",
       " '0057.csv',\n",
       " '0058.csv',\n",
       " '0059.csv',\n",
       " '0060.csv',\n",
       " '0061.csv',\n",
       " '0062.csv',\n",
       " '0063.csv',\n",
       " '0064.csv',\n",
       " '0065.csv',\n",
       " '0066.csv',\n",
       " '0067.csv',\n",
       " '0068.csv',\n",
       " '0069.csv',\n",
       " '0070.csv',\n",
       " '0071.csv',\n",
       " '0072.csv',\n",
       " '0073.csv',\n",
       " '0074.csv',\n",
       " '0075.csv',\n",
       " '0076.csv',\n",
       " '0077.csv',\n",
       " '0078.csv',\n",
       " '0079.csv',\n",
       " '0080.csv',\n",
       " '0081.csv',\n",
       " '0082.csv',\n",
       " '0083.csv',\n",
       " '0084.csv',\n",
       " '0085.csv',\n",
       " '0086.csv',\n",
       " '0087.csv',\n",
       " '0088.csv',\n",
       " '0089.csv',\n",
       " '0090.csv',\n",
       " '0091.csv',\n",
       " '0092.csv',\n",
       " '0093.csv',\n",
       " '0094.csv',\n",
       " '0095.csv',\n",
       " '0096.csv',\n",
       " '0097.csv',\n",
       " '0098.csv',\n",
       " '0099.csv',\n",
       " '0100.csv',\n",
       " '0101.csv',\n",
       " '0102.csv',\n",
       " '0103.csv',\n",
       " '0104.csv',\n",
       " '0105.csv',\n",
       " '0106.csv',\n",
       " '0107.csv',\n",
       " '0108.csv',\n",
       " '0109.csv',\n",
       " '0110.csv',\n",
       " '0111.csv',\n",
       " '0112.csv',\n",
       " '0113.csv',\n",
       " '0114.csv',\n",
       " '0115.csv',\n",
       " '0116.csv',\n",
       " '0117.csv',\n",
       " '0118.csv',\n",
       " '0119.csv',\n",
       " '0120.csv',\n",
       " '0121.csv',\n",
       " '0122.csv',\n",
       " '0123.csv',\n",
       " '0124.csv',\n",
       " '0125.csv',\n",
       " '0126.csv',\n",
       " '0127.csv',\n",
       " '0128.csv',\n",
       " '0129.csv',\n",
       " '0130.csv',\n",
       " '0131.csv',\n",
       " '0132.csv',\n",
       " '0133.csv',\n",
       " '0134.csv',\n",
       " '0135.csv',\n",
       " '0136.csv',\n",
       " '0137.csv',\n",
       " '0138.csv',\n",
       " '0139.csv',\n",
       " '0140.csv',\n",
       " '0141.csv',\n",
       " '0142.csv',\n",
       " '0143.csv',\n",
       " '0144.csv',\n",
       " '0145.csv',\n",
       " '0146.csv',\n",
       " '0147.csv',\n",
       " '0148.csv',\n",
       " '0149.csv',\n",
       " '0150.csv',\n",
       " '0151.csv',\n",
       " '0152.csv',\n",
       " '0153.csv',\n",
       " '0154.csv',\n",
       " '0155.csv',\n",
       " '0156.csv',\n",
       " '0157.csv',\n",
       " '0158.csv',\n",
       " '0159.csv',\n",
       " '0160.csv',\n",
       " '0161.csv',\n",
       " '0162.csv',\n",
       " '0163.csv',\n",
       " '0164.csv',\n",
       " '0165.csv',\n",
       " '0166.csv',\n",
       " '0167.csv',\n",
       " '0168.csv',\n",
       " '0169.csv',\n",
       " '0170.csv',\n",
       " '0171.csv',\n",
       " '0172.csv',\n",
       " '0173.csv',\n",
       " '0174.csv',\n",
       " '0175.csv',\n",
       " '0176.csv',\n",
       " '0177.csv',\n",
       " '0178.csv',\n",
       " '0179.csv',\n",
       " '0180.csv',\n",
       " '0181.csv',\n",
       " '0182.csv',\n",
       " '0183.csv',\n",
       " '0184.csv',\n",
       " '0185.csv',\n",
       " '0186.csv',\n",
       " '0187.csv',\n",
       " '0188.csv',\n",
       " '0189.csv',\n",
       " '0190.csv',\n",
       " '0191.csv',\n",
       " '0192.csv',\n",
       " '0193.csv',\n",
       " '0194.csv',\n",
       " '0195.csv',\n",
       " '0196.csv',\n",
       " '0197.csv',\n",
       " '0198.csv',\n",
       " '0199.csv',\n",
       " '0200.csv',\n",
       " '0201.csv',\n",
       " '0202.csv',\n",
       " '0203.csv',\n",
       " '0204.csv',\n",
       " '0205.csv',\n",
       " '0206.csv',\n",
       " '0207.csv',\n",
       " '0208.csv',\n",
       " '0209.csv',\n",
       " '0210.csv',\n",
       " '0211.csv',\n",
       " '0212.csv',\n",
       " '0213.csv',\n",
       " '0214.csv',\n",
       " '0215.csv',\n",
       " '0216.csv',\n",
       " '0217.csv',\n",
       " '0218.csv',\n",
       " '0219.csv',\n",
       " '0220.csv',\n",
       " '0221.csv',\n",
       " '0222.csv',\n",
       " '0223.csv',\n",
       " '0224.csv',\n",
       " '0225.csv',\n",
       " '0226.csv',\n",
       " '0227.csv',\n",
       " '0228.csv',\n",
       " '0229.csv',\n",
       " '0230.csv',\n",
       " '0231.csv',\n",
       " '0232.csv',\n",
       " '0233.csv',\n",
       " '0234.csv',\n",
       " '0235.csv',\n",
       " '0236.csv',\n",
       " '0237.csv',\n",
       " '0238.csv',\n",
       " '0239.csv',\n",
       " '0240.csv',\n",
       " '0241.csv',\n",
       " '0242.csv',\n",
       " '0243.csv',\n",
       " '0244.csv',\n",
       " '0245.csv',\n",
       " '0246.csv',\n",
       " '0247.csv',\n",
       " '0248.csv',\n",
       " '0249.csv',\n",
       " '0250.csv',\n",
       " '0251.csv',\n",
       " '0252.csv',\n",
       " '0253.csv',\n",
       " '0254.csv',\n",
       " '0255.csv',\n",
       " '0256.csv',\n",
       " '0257.csv',\n",
       " '0258.csv',\n",
       " '0259.csv',\n",
       " '0260.csv',\n",
       " '0261.csv',\n",
       " '0262.csv',\n",
       " '0263.csv',\n",
       " '0264.csv',\n",
       " '0265.csv',\n",
       " '0266.csv',\n",
       " '0267.csv',\n",
       " '0268.csv',\n",
       " '0269.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"{:04d}.csv\".format(x) for x in df_BCN[\"ID\"]] + [\"{:04d}.csv\".format(x) for x in df_NAP[\"ID\"]]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully: 30.\n",
      "Files moved successfully: 18.\n",
      "Files moved successfully: 48.\n",
      "Files moved successfully: 30.\n",
      "Files moved successfully: 30.\n",
      "Files moved successfully: 30.\n"
     ]
    }
   ],
   "source": [
    "# Move all scans from Barcelona and Naples to current folder\n",
    "utils_cleaner.move_files_to_folder(basepath_BCN_FA, basepath_FA)\n",
    "utils_cleaner.move_files_to_folder(basepath_BCN_GM, basepath_GM)\n",
    "utils_cleaner.move_files_to_folder(basepath_BCN_RS, basepath_RS)\n",
    "utils_cleaner.move_files_to_folder(basepath_NAP_FA, basepath_FA)\n",
    "utils_cleaner.move_files_to_folder(basepath_NAP_GM, basepath_GM)\n",
    "utils_cleaner.move_files_to_folder(basepath_NAP_RS, basepath_RS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code will create a **4D _numpy_ array** (`data`) to store the whole dataset:\n",
    "- The shape of the array should be: _(num_subjects, num_nodes, num_nodes, num_matrices)_\n",
    "\n",
    "where:\n",
    "- \"num_subjects\" is 165 + 105 = 270,\n",
    "- \"nun_nodes\" is 76 (parcellation scheme)\n",
    "- \"num_matrices\" is 3 (DTI, GM and rs-fMRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(len(filenames), 76, 76, 3))\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    df = pd.read_csv(os.path.join(basepath_FA, filename), header=None)\n",
    "    data[i,:,:,0] = df.values\n",
    "\n",
    "    df = pd.read_csv(os.path.join(basepath_GM, filename), header=None)\n",
    "    data[i,:,:,1] = df.values\n",
    "\n",
    "    df = pd.read_csv(os.path.join(basepath_RS, filename), header=None)\n",
    "    data[i,:,:,2] = df.values\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Save the data to a .npy file\n",
    "np.save(os.path.join(basepath, 'data.npy'), data)\n",
    "print(\"Data saved to data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the full array is too heavy to be uploaded to Github, we will separate each scan type to a different data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = './'\n",
    "basepath_final = os.path.join(basepath, 'data/')\n",
    "\n",
    "scan_types = [\"FA\", \"GM\", \"RS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils_cleaner' from '/home/merles/Documents/git/utils_cleaner.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all FA scans as ./data/FA_original.npy\n",
      "Saved all GM scans as ./data/GM_original.npy\n",
      "Saved all RS scans as ./data/RS_original.npy\n"
     ]
    }
   ],
   "source": [
    "utils_cleaner.save_3d_slices(data, basepath_final, scan_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
