{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With automated change of scan type and abs values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that max values for all scan types are 1 and min are 0 for FA and GM, and ~-1 for RS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import utils_thresholds\n",
    "import utils_preproc\n",
    "import sparsification_utils\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only to reload the utils_thresholds import\n",
    "import importlib\n",
    "importlib.reload(utils_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "basepath = './'\n",
    "basepath_data = os.path.join(basepath, 'data/data.npy')\n",
    "basepath_th = os.path.join(basepath, 'results/thresholded/')\n",
    "basepath_spar = os.path.join(basepath, 'results/sparsified/')\n",
    "basepath_plots = os.path.join(basepath, 'results/plots/')\n",
    "basepath_measures = os.path.join(basepath, 'results/measures/')\n",
    "\n",
    "data = np.load(basepath_data)\n",
    "print(f'Data succesfully loaded: {data.shape}')\n",
    "\n",
    "scan_types = [\"FA\", \"GM\", \"RS\"]\n",
    "\n",
    "all_nodes = {i for i in range(76)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FA: Search around 0.3\n",
    "FA_thresholds = [0, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "# GM: Search around 0.55\n",
    "GM_thresholds = [0, 0.5, 0.55, 0.575, 0.6]\n",
    "# RS: Search between 0.1 and 0.3\n",
    "RS_thresholds = [0, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "all_thresholds = [FA_thresholds, GM_thresholds, RS_thresholds]\n",
    "all_thr_for_node = [[0, 0.4, 0.45, 0.5], [0, 0.5, 0.55, 0.575, 0.6], [0, 0.1, 0.15, 0.2, 0.25]]\n",
    "#all_thr_for_node = [[0], [0, 0.5], [0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_type = 2\n",
    "graph_set = data[:,:,:,scan_type]\n",
    "print(f'Using {scan_types[scan_type]} scans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Thresholding graphs...\")\n",
    "thresholded_graphs = utils_thresholds.calculate_thresholded_graphs(graph_set, all_thresholds[scan_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './'#basepath_plots + \"thr_\" + scan_types[scan_type] + \"_graph_measures_\"\n",
    "original_graph_info = utils_preproc.get_number_of_nodes_and_edges(graph_set)\n",
    "graph_measures = utils_preproc.plot_graph_metrics(thresholded_graphs, original_graph_info, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # Define how many top nodes you want to consider\n",
    "\n",
    "save_path = basepath_plots + \"thr_\" + scan_types[scan_type] + \"_node_measures_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 0.1, 0.15, 0.2, 0.25, 0.3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (\"Calculating node measures...\")\n",
    "thresholded_graphs_including_originals = thresholded_graphs#utils_preproc.append_original_graphs_to_threshold(thresholded_graphs, graph_set)\n",
    "thresholded_graphs_including_originals.keys()\n",
    "# TODO: ATENCIÓ: això ja no cal fer-ho, elq es pot fer és no guardar els originals quan els guardo com a tal, però està bé guardar totes les mesures igualment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 0.1, 0.15, 0.2, 0.25])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_graphs_for_node_metrics = {key: thresholded_graphs_including_originals[key] for key in all_thr_for_node[scan_type]}\n",
    "thresholded_graphs_for_node_metrics.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STILL isn't able to calculate the measures for RS scans for the original graphs.\n",
    "\n",
    "Tant pels originals tal qual com per un cop thresholded amb thr = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adj_mat \u001b[38;5;129;01min\u001b[39;00m graph_set:\n\u001b[1;32m      2\u001b[0m     G \u001b[38;5;241m=\u001b[39m utils_preproc\u001b[38;5;241m.\u001b[39madjacency_matrix_to_graph(adj_mat)\n\u001b[0;32m----> 3\u001b[0m     measures \u001b[38;5;241m=\u001b[39m \u001b[43mutils_preproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_node_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/git/utils_preproc.py:444\u001b[0m, in \u001b[0;36mcalculate_node_measures\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    442\u001b[0m closeness_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mcloseness_centrality(G)\n\u001b[1;32m    443\u001b[0m eigenvector_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39meigenvector_centrality(G)\n\u001b[0;32m--> 444\u001b[0m pagerank_centrality \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Store centrality measures in a dictionary for easy access\u001b[39;00m\n\u001b[1;32m    447\u001b[0m centralities \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDegree_Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m: degree_centrality,\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBetweenness_Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m: betweenness_centrality,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPageRank\u001b[39m\u001b[38;5;124m'\u001b[39m: pagerank_centrality\n\u001b[1;32m    453\u001b[0m }\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:108\u001b[0m, in \u001b[0;36mpagerank\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagerank\u001b[39m(\n\u001b[1;32m     10\u001b[0m     G,\n\u001b[1;32m     11\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     dangling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m ):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpagerank_scipy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersonalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdangling\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:508\u001b[0m, in \u001b[0;36mpagerank_scipy\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m<\u001b[39m N \u001b[38;5;241m*\u001b[39m tol:\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(nodelist, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, x)))\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mPowerIterationFailedConvergence(max_iter)\n",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "for adj_mat in graph_set:\n",
    "    G = utils_preproc.adjacency_matrix_to_graph(adj_mat)\n",
    "    measures = utils_preproc.calculate_node_measures(G)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(thr)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graph_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(thresholded_graphs_for_node_metrics[thr])):\n\u001b[0;32m----> 4\u001b[0m     measures \u001b[38;5;241m=\u001b[39m \u001b[43mutils_preproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_node_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresholded_graphs_for_node_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgraph_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#print(thr, graph_idx, measures)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/utils_preproc.py:444\u001b[0m, in \u001b[0;36mcalculate_node_measures\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    442\u001b[0m closeness_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mcloseness_centrality(G)\n\u001b[1;32m    443\u001b[0m eigenvector_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39meigenvector_centrality(G)\n\u001b[0;32m--> 444\u001b[0m pagerank_centrality \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Store centrality measures in a dictionary for easy access\u001b[39;00m\n\u001b[1;32m    447\u001b[0m centralities \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDegree_Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m: degree_centrality,\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBetweenness_Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m: betweenness_centrality,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPageRank\u001b[39m\u001b[38;5;124m'\u001b[39m: pagerank_centrality\n\u001b[1;32m    453\u001b[0m }\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:108\u001b[0m, in \u001b[0;36mpagerank\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagerank\u001b[39m(\n\u001b[1;32m     10\u001b[0m     G,\n\u001b[1;32m     11\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     dangling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m ):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpagerank_scipy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersonalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdangling\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:508\u001b[0m, in \u001b[0;36mpagerank_scipy\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m<\u001b[39m N \u001b[38;5;241m*\u001b[39m tol:\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(nodelist, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, x)))\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mPowerIterationFailedConvergence(max_iter)\n",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "for thr in thresholded_graphs_for_node_metrics.keys():\n",
    "    print(thr)\n",
    "    for graph_idx in range(len(thresholded_graphs_for_node_metrics[thr])):\n",
    "        measures = utils_preproc.calculate_node_measures(thresholded_graphs_for_node_metrics[thr][graph_idx])\n",
    "        #print(thr, graph_idx, measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m node_measures \u001b[38;5;241m=\u001b[39m \u001b[43mutils_preproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_node_measures_per_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresholded_graphs_for_node_metrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/utils_preproc.py:470\u001b[0m, in \u001b[0;36mcalculate_node_measures_per_graph\u001b[0;34m(thresholded_graphs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Iterate through each graph in the current threshold\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filtered_graph \u001b[38;5;129;01min\u001b[39;00m graphs:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# Calculate measures for this graph\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     measures \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_node_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# Sort the node measures by node name\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m measure_name, measure_values \u001b[38;5;129;01min\u001b[39;00m measures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;66;03m# Sort the dictionary based on the node name (keys)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/utils_preproc.py:444\u001b[0m, in \u001b[0;36mcalculate_node_measures\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    442\u001b[0m closeness_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mcloseness_centrality(G)\n\u001b[1;32m    443\u001b[0m eigenvector_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39meigenvector_centrality(G)\n\u001b[0;32m--> 444\u001b[0m pagerank_centrality \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Store centrality measures in a dictionary for easy access\u001b[39;00m\n\u001b[1;32m    447\u001b[0m centralities \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDegree_Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m: degree_centrality,\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBetweenness_Centrality\u001b[39m\u001b[38;5;124m'\u001b[39m: betweenness_centrality,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPageRank\u001b[39m\u001b[38;5;124m'\u001b[39m: pagerank_centrality\n\u001b[1;32m    453\u001b[0m }\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:108\u001b[0m, in \u001b[0;36mpagerank\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagerank\u001b[39m(\n\u001b[1;32m     10\u001b[0m     G,\n\u001b[1;32m     11\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     dangling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m ):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpagerank_scipy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersonalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdangling\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:508\u001b[0m, in \u001b[0;36mpagerank_scipy\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m<\u001b[39m N \u001b[38;5;241m*\u001b[39m tol:\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(nodelist, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, x)))\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mPowerIterationFailedConvergence(max_iter)\n",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "node_measures = utils_preproc.calculate_node_measures_per_graph(thresholded_graphs_for_node_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    print(\"Averaging...\")\n",
    "    avg_node_measures = utils_preproc.calculate_average_node_measures_per_threshold(node_measures)\n",
    "    common_nodes = utils_preproc.find_common_nodes_across_metrics(avg_node_measures, N)\n",
    "    all_common_nodes = set.intersection(*common_nodes.values())\n",
    "\n",
    "    print(\"Plotting!\")\n",
    "    utils_preproc.plot_node_metrics_per_threshold(all_nodes, all_common_nodes, avg_node_measures, save_path)\n",
    "\n",
    "    # End time\n",
    "    end_time = time.time()\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    # Print the elapsed time\n",
    "    if elapsed_time > 60:\n",
    "        print(f\"Script took {elapsed_time/60:.2f} minutes to run.\")\n",
    "    else:\n",
    "        print(f\"Script took {elapsed_time:.2f} seconds to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAIT!!\n",
    "\n",
    "Clar, hi ha grafs amb valors negatius als edges però ens interessa el valor absolut!!!!!\n",
    "\n",
    "He borrat els outputs sense voler però estan guardats a la backup '20241023 thr_main_notebook.ipynb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
